{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tách dữ liệu để huấn luyện và kiểm thử\n",
    "Mục đích của bước này là chia dữ liệu làm 2 phần, một phần để huấn luyện và phần còn lại coi như là thực tế và để đánh giá cuối cùng.\n",
    "- Đầu vào: đường dẫn đến file dữ liệu đã crawl\n",
    "- Đầu ra: 1 file train.csv và 1 file test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data_path, train_data_path, test_data_path):\n",
    "    data_df = pd.read_csv(data_path, index_col=0, sep='\\t')\n",
    "    data_df.label.astype(int)\n",
    "    \n",
    "    train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=0)\n",
    "    train_df.to_csv(train_data_path)\n",
    "    test_df.to_csv(test_data_path)\n",
    "    \n",
    "split_train_test('../data/csv/vietnamnews.csv', '../data/csv/train.csv', '../data/csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../data/csv/train.csv', index_col = 0)\n",
    "\n",
    "y_sr = data_df[\"label\"]\n",
    "X_df = data_df.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Thống kê dữ liệu tập huấn luyện\n",
    "- Kiểm tra các giá trị thiếu\n",
    "- Kiểm tra độ dài trung bình của nội dung và tiêu đề của các thể loại, và vẽ biểu đồ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Chairman of the State Duma of the Federal Assembly of the Russian Federation Vyacheslav Viktorovich Volodin. — VNA/VNS Photo'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4436</td>\n",
       "      <td>4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>4436</td>\n",
       "      <td>4435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>'VN, Nigeria to increase two-way commerce, inv...</td>\n",
       "      <td>''</td>\n",
       "      <td>top</td>\n",
       "      <td>'VN team wins ASEAN Data Science Explorers 2019'</td>\n",
       "      <td>'Chairman of the State Duma of the Federal Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  text\n",
       "count                                                4299  4299\n",
       "unique                                               4299  4296\n",
       "top     'VN, Nigeria to increase two-way commerce, inv...    ''\n",
       "freq                                                    1     4",
       "                                                   title  \\\n",
       "count                                               4436   \n",
       "unique                                              4436   \n",
       "top     'VN team wins ASEAN Data Science Explorers 2019'   \n",
       "freq                                                   1   \n",
       "\n",
       "                                                     text  \n",
       "count                                                4436  \n",
       "unique                                               4435  \n",
       "top     'Chairman of the State Duma of the Federal Ass...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_insight(X_df):\n",
    "    raise NotImplementedError\n",
    "\n",
    "myset = set()\n",
    "for index, row in X_df.iterrows():\n",
    "    text = row['text']\n",
    "    title = row['title']\n",
    "    prev_len = len(myset)\n",
    "    myset.add(text)\n",
    "    if len(myset) == prev_len:\n",
    "        print(text)\n",
    "        \n",
    "X_df.describe()\n",
    "\n",
    "# from requests_html import HTMLSession\n",
    "# sess = HTMLSession()\n",
    "\n",
    "# r = sess.get('https://vietnamnews.vn/politics-laws/570613/trial-of-da-nangs-former-top-leaders-opens.html')\n",
    "# findable_html = r.html\n",
    "# findable_html.find('.vnnews-text-post', first=True).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module được thực hiện đầu Pipeline, xóa các khoảng trắng liên tiếp, các ký tự: \\n, \\t, ...\n",
    "\n",
    "class RemoveIrrelevant(BaseEstimator, TransformerMixin):\n",
    "    @staticmethod\n",
    "    def clean_str(string):\n",
    "        string = re.sub(r\"\\\\xa0\", \" \", string)\n",
    "        string = re.sub(r\"\\'s\", \"\", string)\n",
    "        string = re.sub(r\"\\'ve\", \"\", string)\n",
    "        string = re.sub(r\"n\\'t\", \"\", string)\n",
    "        string = re.sub(r\"\\'re\", \"\", string)\n",
    "        string = re.sub(r\"\\'d\", \"\", string)\n",
    "        string = re.sub(r\"\\'ll\", \"\", string)\n",
    "        string = re.sub(r\"'\", \"\", string)\n",
    "        string = re.sub(r\"\\\\n\", \" \", string)\n",
    "        string = re.sub(r\"\\\\t\", \" \", string)\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string) # Consecutive spaces\n",
    "        return string.strip()\n",
    "    \n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        transform_X_df = X_df.copy()\n",
    "        transform_X_df['title'] = transform_X_df['title'].apply(lambda x: self.clean_str(x))\n",
    "        transform_X_df['text'] = transform_X_df['text'].apply(lambda x: self.clean_str(x))\n",
    "        return transform_X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'National Assembly (NA) Chairwoman Nguyễn Thị Kim Ngân (L) arrives\\xa0at Minsk International Airport on Thursday morning (local time). — VNA/VNS Photo Trọng Đức\\nMINSK —\\xa0National Assembly (NA) Chairwoman Nguyễn Thị Kim Ngân and her entourage arrived at Minsk International Airport yesterday morning, beginning a three-day official visit to Belarus.\\nThe trip is made at the invitation of Chairman of the Council of the Republic Mikhail Myasnikovich and Chairman of the House of Representatives of the NA of\\xa0Belarus Vladimir Andreichenko.\\n\\nWelcoming the Vietnamese delegation at the airport were Deputy Chairman of the Council of the Republic Isachenko Anatoly Mikhailovich, other officials of the Council, and Vietnamese Ambassador to Belarus Phạm Hải.\\n\\nThe first official trip to Belarus by Chairwoman Ngân aims to enhance the traditional friendship and multifaceted cooperation between the two countries and push ahead with the implementation of cooperation agreements between the two parliaments.\\n\\nIn 2019, the two countries’ relations have enjoyed strong developments with cooperation enhanced in all spheres.\\n\\nIn politics, Việt Nam and Belarus have cooperated closely and supported each other at the United Nations, the Non-Aligned Movement and many other international forums and\\xa0organisations.\\n\\nIn the economic field, bilateral trade has grown well, from US$107.15 million in 2014 to $153.4 million in just the first nine months of 2019. Trade revenue is expected to reach $200 million this year after standing at around $100 million USD for many years.\\n\\nBilateral collaboration has also been fruitful in many other fields such as education-training, tourism, culture, science-technology, labour, and people-to-people exchange.—VNS'\n",
      "\n",
      "\n",
      "National Assembly (NA) Chairwoman Nguyễn Thị Kim Ngân (L) arrives at Minsk International Airport on Thursday morning (local time). — VNA/VNS Photo Trọng Đức MINSK — National Assembly (NA) Chairwoman Nguyễn Thị Kim Ngân and her entourage arrived at Minsk International Airport yesterday morning, beginning a three-day official visit to Belarus. The trip is made at the invitation of Chairman of the Council of the Republic Mikhail Myasnikovich and Chairman of the House of Representatives of the NA of Belarus Vladimir Andreichenko. Welcoming the Vietnamese delegation at the airport were Deputy Chairman of the Council of the Republic Isachenko Anatoly Mikhailovich, other officials of the Council, and Vietnamese Ambassador to Belarus Phạm Hải. The first official trip to Belarus by Chairwoman Ngân aims to enhance the traditional friendship and multifaceted cooperation between the two countries and push ahead with the implementation of cooperation agreements between the two parliaments. In 2019, the two countries’ relations have enjoyed strong developments with cooperation enhanced in all spheres. In politics, Việt Nam and Belarus have cooperated closely and supported each other at the United Nations, the Non-Aligned Movement and many other international forums and organisations. In the economic field, bilateral trade has grown well, from US$107.15 million in 2014 to $153.4 million in just the first nine months of 2019. Trade revenue is expected to reach $200 million this year after standing at around $100 million USD for many years. Bilateral collaboration has also been fruitful in many other fields such as education-training, tourism, culture, science-technology, labour, and people-to-people exchange.—VNS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1726"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST CELL\n",
    "pl = RemoveIrrelevant()\n",
    "transform_X = pl.transform(X_df)\n",
    "print(X_df['text'][5])\n",
    "print('\\n')\n",
    "print(transform_X['text'][5])\n",
    "len(transform_X['text'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.  Chọn các đặc trưng\n",
    "+ Số ký tự văn bản\n",
    "+ Số từ trong văn bản\n",
    "+ Số lượng dấu cảm thán (!, ?)\n",
    "+ Số chữ cái viết hoa\n",
    "+ Số chữ cái viết thường\n",
    "+ Các giá trị TF-IDF cho các từ trong văn bản (có xử lý văn bản trước đó), có những ưu tiên cho các từ trong title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Các đặc trưng cơ bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumTextCharFeature(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        return X_df['text'].apply(lambda x: len(x)).values\n",
    "    \n",
    "class NumTextTokenFeature(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        return X_df['text'].apply(lambda x: len(x.split(' '))).values\n",
    "    \n",
    "    \n",
    "class NumTextExclamationMarkFeature(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        return X_df['text'].apply(lambda x: (x.count('!')+x.count('?'))).values\n",
    "    \n",
    "class NumTextLowerCaseFeature(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        return X_df['text'].str.count(r'[a-z]').values\n",
    "\n",
    "class NumTextUpperCaseFeature(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        return X_df['text'].str.count(r'[A-Z]').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2178 1902 1351 ... 1189 1469 3680]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# TEST CELL\n",
    "pl = NumTextCharFeature()\n",
    "transform_X = pl.transform(X_df)\n",
    "print(transform_X)\n",
    "\n",
    "pl = NumTextExclamationMarkFeature()\n",
    "transform_X = pl.transform(X_df)\n",
    "print(transform_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Thử nghiệm TF-IDF trên 2 cột title và text và đưa ra vài heuristic về sự ưu tiên cho cột title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các module tiền xử lý trước khi tính tf-idf\n",
    "\n",
    "class RemoveTone(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        pass\n",
    "    \n",
    "class LowerCase(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.  Pipeline cho quá trình tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = FeatureUnion([('num_text_char_feature', NumTextCharFeature()),\n",
    "                      ('num_text_token_feature', NumTextTokenFeature()),\n",
    "                      ('num_text_exclamation_mark_feature', NumTextExclamationMarkFeature()),\n",
    "                      ('num_text_lower_case_feature', NumTextLowerCaseFeature()),\n",
    "                      ('num_text_upper_case_feature', NumTextUpperCaseFeature())]) # !!!add tf-idf feature\n",
    "\n",
    "preprocess_pipeline = Pipeline(steps=[('remove_irrelevant', RemoveIrrelevant()),\n",
    "                                      ('union', union)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Thiết kế mô hình hoàn chỉnh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Chia k fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_k_folds(k):\n",
    "    return KFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Khai báo các classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = []\n",
    "\n",
    "# classifier parameters config\n",
    "hyper_params_cfg = {\n",
    "    'mlp':{\n",
    "        'hidden_layer_sizes': [],\n",
    "        'activation': [],\n",
    "        'solver': []\n",
    "    },\n",
    "    'svm':{\n",
    "        'param1': [],\n",
    "        'param2': []\n",
    "    }\n",
    "}\n",
    "model = linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khi train mới fit_transform và transform tại mỗi vòng for của fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[3036. 1064. 2662. ...   61.  141.  134.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d0f31e215f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                     ('classifier', model)])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_valid_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1532\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[3036. 1064. 2662. ...   61.  141.  134.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "k_fold = split_k_folds(k=5)\n",
    "scores = []\n",
    "\n",
    "for train_index, valid_index in k_fold.split(X_df):\n",
    "    X_train, X_valid = X_df.iloc[train_index], X_df.iloc[valid_index]\n",
    "    y_train, y_valid = y_sr.iloc[train_index], y_sr.iloc[valid_index]\n",
    "#     print(X_train[:10])\n",
    "#     print('\\n')\n",
    "#     print(y_train[:10])\n",
    "    \n",
    "    full_pipeline = Pipeline(steps=[('preprocess_pipeline', preprocess_pipeline), \n",
    "                                    ('classifier', model)])\n",
    "    \n",
    "    full_pipeline.fit_transform(X_train, y_train)\n",
    "    y_valid_predict = full_pipeline.predict(X_val)\n",
    "    \n",
    "    score = metrics.accuracy_score(y_valid_predict, y_valid)\n",
    "    scores.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=10)\n",
    "    plt.yticks(tick_marks, classes, fontsize=10)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=18)\n",
    "    plt.xlabel('Predicted label', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_confusion_matrix(cnf_matrix, classes=text_labels, title=\"Confusion matrix\",cmap=\"Greens\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
