{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from newspaper import Article\n",
    "import json\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump json to dict\n",
    "urls_file = open('../data/urls/vietnamnews_urls.json', 'r')\n",
    "all_urls = json.load(urls_file)\n",
    "urls_file.close()\n",
    "\n",
    "n_duplicate_url = 0\n",
    "myset = set()\n",
    "for key in all_urls.keys():\n",
    "    for url in all_urls[key]:\n",
    "        prev_len = len(myset)\n",
    "        myset.add(url)\n",
    "        if prev_len == len(myset):\n",
    "            n_duplicate_url += 1\n",
    "            \n",
    "assert n_duplicate_url == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_raw_feature(article_url, session):\n",
    "    r = session.get(article_url)\n",
    "    findable_html = r.html\n",
    "    \n",
    "    title = findable_html.find('.vnnews-tt-post', first=True).text\n",
    "    text = findable_html.find('.vnnews-text-post', first=True).text\n",
    "    \n",
    "    return repr(text), repr(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================politics-laws====================\n",
      "Proccess 50 article(s)\n",
      "Proccess 100 article(s)\n",
      "Proccess 150 article(s)\n",
      "Proccess 200 article(s)\n",
      "Proccess 250 article(s)\n",
      "Proccess 300 article(s)\n",
      "Proccess 350 article(s)\n",
      "Proccess 400 article(s)\n",
      "Proccess 450 article(s)\n",
      "Proccess 500 article(s)\n",
      "Proccess 550 article(s)\n",
      "Proccess 600 article(s)\n",
      "Proccess 650 article(s)\n",
      "Proccess 700 article(s)\n",
      "Proccess 750 article(s)\n",
      "Proccess 800 article(s)\n",
      "Proccess 850 article(s)\n",
      "====================society====================\n",
      "Proccess 900 article(s)\n",
      "Proccess 950 article(s)\n",
      "Proccess 1000 article(s)\n",
      "Proccess 1050 article(s)\n",
      "Proccess 1100 article(s)\n",
      "Proccess 1150 article(s)\n",
      "Proccess 1200 article(s)\n",
      "Proccess 1250 article(s)\n",
      "Proccess 1300 article(s)\n",
      "Proccess 1350 article(s)\n",
      "Proccess 1400 article(s)\n",
      "Proccess 1450 article(s)\n",
      "Proccess 1500 article(s)\n",
      "Proccess 1550 article(s)\n",
      "Proccess 1600 article(s)\n",
      "Proccess 1650 article(s)\n",
      "Proccess 1700 article(s)\n",
      "Proccess 1750 article(s)\n",
      "====================economy====================\n",
      "Proccess 1800 article(s)\n",
      "Proccess 1850 article(s)\n",
      "Proccess 1900 article(s)\n",
      "Proccess 1950 article(s)\n",
      "Proccess 2000 article(s)\n",
      "Proccess 2050 article(s)\n",
      "Proccess 2100 article(s)\n",
      "Proccess 2150 article(s)\n",
      "Proccess 2200 article(s)\n",
      "Proccess 2250 article(s)\n",
      "Proccess 2300 article(s)\n",
      "Proccess 2350 article(s)\n",
      "Proccess 2400 article(s)\n",
      "Proccess 2450 article(s)\n",
      "Proccess 2500 article(s)\n",
      "Proccess 2550 article(s)\n",
      "Proccess 2600 article(s)\n",
      "Proccess 2650 article(s)\n",
      "====================sports====================\n",
      "Proccess 2700 article(s)\n",
      "Proccess 2750 article(s)\n",
      "Proccess 2800 article(s)\n",
      "Proccess 2850 article(s)\n",
      "Proccess 2900 article(s)\n",
      "Proccess 2950 article(s)\n",
      "Proccess 3000 article(s)\n",
      "Proccess 3050 article(s)\n",
      "Proccess 3100 article(s)\n",
      "Proccess 3150 article(s)\n",
      "Proccess 3200 article(s)\n",
      "Proccess 3250 article(s)\n",
      "Proccess 3300 article(s)\n",
      "Proccess 3350 article(s)\n",
      "Proccess 3400 article(s)\n",
      "Proccess 3450 article(s)\n",
      "Proccess 3500 article(s)\n",
      "Proccess 3550 article(s)\n",
      "====================environment====================\n",
      "Proccess 3600 article(s)\n",
      "Proccess 3650 article(s)\n",
      "Proccess 3700 article(s)\n",
      "Proccess 3750 article(s)\n",
      "Proccess 3800 article(s)\n",
      "Proccess 3850 article(s)\n",
      "Proccess 3900 article(s)\n",
      "Proccess 3950 article(s)\n",
      "Proccess 4000 article(s)\n",
      "Proccess 4050 article(s)\n",
      "Proccess 4100 article(s)\n",
      "Proccess 4150 article(s)\n",
      "Proccess 4200 article(s)\n",
      "Proccess 4250 article(s)\n",
      "Proccess 4300 article(s)\n",
      "Proccess 4350 article(s)\n",
      "Proccess 4400 article(s)\n",
      "Proccess 4450 article(s)\n",
      "====================life-style====================\n",
      "Proccess 4500 article(s)\n",
      "Proccess 4550 article(s)\n",
      "Proccess 4600 article(s)\n",
      "Proccess 4650 article(s)\n",
      "Proccess 4700 article(s)\n",
      "Proccess 4750 article(s)\n",
      "Proccess 4800 article(s)\n",
      "Proccess 4850 article(s)\n",
      "Proccess 4900 article(s)\n",
      "Proccess 4950 article(s)\n",
      "Proccess 5000 article(s)\n",
      "Proccess 5050 article(s)\n",
      "Proccess 5100 article(s)\n",
      "Proccess 5150 article(s)\n",
      "Proccess 5200 article(s)\n",
      "Proccess 5250 article(s)\n",
      "Proccess 5300 article(s)\n",
      "Proccess 5350 article(s)\n"
     ]
    }
   ],
   "source": [
    "# parse article\n",
    "session = HTMLSession()\n",
    "csv_file = open('../data/csv/vietnamnews.csv', 'w', encoding='utf-8')\n",
    "csv_file.write(f'id\\ttitle\\ttext\\tlabel\\n')\n",
    "\n",
    "n_failed_articles = 0\n",
    "n_successful_articles = 0\n",
    "n_duplicate_articles = 0\n",
    "\n",
    "label_id = 0\n",
    "title_set = set()\n",
    "\n",
    "for key in all_urls.keys():\n",
    "    print('='*20 + key + '='*20)\n",
    "    for url in all_urls[key]:\n",
    "        try:\n",
    "            text, title = get_article_raw_feature(url, session)\n",
    "            prev_len = len(title_set)\n",
    "            title_set.add(title)\n",
    "            if prev_len != len(title_set):\n",
    "                csv_file.write(f'{n_successful_articles}\\t{title}\\t{text}\\t{label_id}\\n')\n",
    "                n_successful_articles += 1\n",
    "\n",
    "                if n_successful_articles % 50 == 0:\n",
    "                    print('Proccess {} article(s)'.format(n_successful_articles))\n",
    "            else:\n",
    "                n_duplicate_articles += 1\n",
    "            \n",
    "        except:\n",
    "            n_failed_articles += 1\n",
    "    \n",
    "    label_id += 1\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successful articles:  5374\n",
      "Number of duplicate articles:  26\n",
      "Number of failed articles:  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of successful articles: ', n_successful_articles)\n",
    "print('Number of duplicate articles: ', n_duplicate_articles)\n",
    "print('Number of failed articles: ', n_failed_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
