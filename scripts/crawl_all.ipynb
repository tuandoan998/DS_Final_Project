{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import json\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_url = 'https://vietnamnews.vn/politics-laws'\n",
    "society_url = 'https://vietnamnews.vn/society'\n",
    "economy_url = 'https://vietnamnews.vn/economy'\n",
    "sports_url = 'https://vietnamnews.vn/sports'\n",
    "environment_url = 'https://vietnamnews.vn/environment'\n",
    "life_url = 'https://vietnamnews.vn/life-style'\n",
    "\n",
    "categories = [politics_url, society_url, economy_url, sports_url, environment_url, life_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_information(article_url, session):\n",
    "    r = session.get(article_url)\n",
    "    findable_html = r.html\n",
    "    \n",
    "    title = findable_html.find('.vnnews-tt-post', first=True).text\n",
    "    text = findable_html.find('.vnnews-text-post', first=True).text\n",
    "    article_time = findable_html.find('.vnnews-time-post', first=True).text\n",
    "    \n",
    "    return repr(text), repr(title), repr(article_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_time(article_time, time_list):\n",
    "    for t in time_list:\n",
    "        if article_time.find(t) != -1:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(label_id, category_url, num_pages, csv_file, start_time):\n",
    "    browser = webdriver.Chrome('./chromedriver')\n",
    "    browser.get(category_url)\n",
    "    \n",
    "    session = HTMLSession()\n",
    "\n",
    "    n_failed_articles = 0\n",
    "    n_successful_articles = 0\n",
    "    \n",
    "    n_duplicate_articles = 0\n",
    "    n_invalid_times = 0\n",
    "    n_invalid_text = 0\n",
    "    \n",
    "    total_invalid_articles = 0\n",
    "    \n",
    "    title_set = set()\n",
    "    errors_set = set()\n",
    "    urls_set = set()\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        try:\n",
    "            articles = browser.find_element_by_class_name('vnnews-list-news').find_elements_by_tag_name(\"li\")\n",
    "            for article in articles:\n",
    "                url = article.find_element_by_tag_name('a').get_attribute('href')\n",
    "                urls_set.add(url)\n",
    "                try:\n",
    "                    text, title, article_time = get_article_information(url, session)\n",
    "                    prev_len = len(title_set)\n",
    "                    title_set.add(title)\n",
    "                    if is_in_time(article_time, ['2017', '2018', '2019']) and prev_len != len(title_set) \\\n",
    "                    and len(text) > 20:\n",
    "                        csv_file.write(f'{n_successful_articles}\\t{title}\\t{text}\\t{label_id}\\n')\n",
    "                        n_successful_articles += 1\n",
    "                    else:\n",
    "                        if is_in_time(article_time, ['2017', '2018', '2019']) == False:\n",
    "                            n_invalid_times += 1\n",
    "                        if len(text) <= 20:\n",
    "                            n_invalid_text += 1\n",
    "                        if prev_len == len(title_set):\n",
    "                            n_duplicate_articles += 1\n",
    "                        \n",
    "                        total_invalid_articles += 1\n",
    "                except Exception as e:\n",
    "                    errors_set.add(e)\n",
    "                    n_failed_articles += 1\n",
    "            \n",
    "            if (i+1) % 10 == 0:\n",
    "                print('='*50)\n",
    "                print(\"Crawled {} pages\".format(i+1))\n",
    "                print('Number of urls: ', len(urls_set))\n",
    "                print('Number of successful articles: ', n_successful_articles)\n",
    "                print('Number of duplicate articles: ', n_duplicate_articles)\n",
    "                print('Number of invalid time articles: ', n_invalid_times)\n",
    "                print('Number of invalid text articles: ', n_invalid_text)\n",
    "                print('Total invalid articles: ', total_invalid_articles)\n",
    "                print('Number of failed articles: ', n_failed_articles)\n",
    "                print('Fail reasons: ', errors_set)\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                print('Time elapsed: {}m {}s'.format(int(elapsed_time//60), int(elapsed_time%60)))\n",
    "                print('='*50)\n",
    "            browser.find_element_by_class_name(\"vnnews-paging\").find_elements_by_tag_name(\"a\")[4].click()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Terminate at {} pages'.format(i+1))\n",
    "            break\n",
    "    \n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Crawling politics-laws ...\n",
      "==================================================\n",
      "Crawled 10 pages\n",
      "Number of urls:  90\n",
      "Number of successful articles:  84\n",
      "Number of duplicate articles:  0\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  6\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 4m 16s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 20 pages\n",
      "Number of urls:  180\n",
      "Number of successful articles:  174\n",
      "Number of duplicate articles:  0\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  6\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 7m 13s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 30 pages\n",
      "Number of urls:  270\n",
      "Number of successful articles:  262\n",
      "Number of duplicate articles:  2\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  8\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 12m 6s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 40 pages\n",
      "Number of urls:  360\n",
      "Number of successful articles:  352\n",
      "Number of duplicate articles:  2\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  8\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 17m 25s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 50 pages\n",
      "Number of urls:  450\n",
      "Number of successful articles:  441\n",
      "Number of duplicate articles:  3\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  9\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 22m 9s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 60 pages\n",
      "Number of urls:  540\n",
      "Number of successful articles:  531\n",
      "Number of duplicate articles:  3\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  9\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 26m 56s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 70 pages\n",
      "Number of urls:  630\n",
      "Number of successful articles:  619\n",
      "Number of duplicate articles:  5\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  11\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 31m 41s\n",
      "==================================================\n",
      "==================================================\n",
      "Crawled 80 pages\n",
      "Number of urls:  720\n",
      "Number of successful articles:  708\n",
      "Number of duplicate articles:  6\n",
      "Number of invalid time articles:  6\n",
      "Number of invalid text articles:  0\n",
      "Total invalid articles:  12\n",
      "Number of failed articles:  0\n",
      "Fail reasons:  set()\n",
      "Time elapsed: 36m 21s\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "csv_file = open('../data/csv/vietnamnews.csv', 'w', encoding='utf-8')\n",
    "csv_file.write(f'id\\ttitle\\ttext\\tlabel\\n')\n",
    "start_time = time.time()\n",
    "\n",
    "for label_id, category in enumerate(categories):\n",
    "    category_name = category.split('/')[-1]\n",
    "    print(f'... Crawling {category_name} ...')\n",
    "    get_all(label_id, category, 150, csv_file, start_time)\n",
    "    print('='*50)\n",
    "    \n",
    "csv_file.close()\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Finish after: {}m {}s'.format(int(elapsed_time//60), int(elapsed_time%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
